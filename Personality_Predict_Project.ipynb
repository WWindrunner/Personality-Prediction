{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T23:26:27.255434Z",
     "start_time": "2023-12-03T23:26:27.178618Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Credit https://www.kaggle.com/code/ssakthisaravanan/nlp-r2-mbti-personality-predictor-using-ml\n",
    "\n",
    "# Data Analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import wordcloud\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Text Processing\n",
    "import re\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Machine Learning packages\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Model training and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Ignore noise warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T23:26:27.670928Z",
     "start_time": "2023-12-03T23:26:27.180623Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "MBTI_DS = pd.read_csv(\"mbti_1.csv\")\n",
    "MBTI_DS.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T23:26:27.674682Z",
     "start_time": "2023-12-03T23:26:27.670928Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "MBTI_DS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T23:26:27.686115Z",
     "start_time": "2023-12-03T23:26:27.674682Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "types = np.unique(np.array(MBTI_DS['type']))\n",
    "print(\"The Unique values 'type' of personality column\",types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T23:26:27.847437Z",
     "start_time": "2023-12-03T23:26:27.682051Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "total = MBTI_DS.groupby(['type']).count()\n",
    "plt.figure(figsize = (10,3))\n",
    "plt.bar(np.array(total.index), height = total['posts'],)\n",
    "plt.xlabel('Personality types', size = 12)\n",
    "plt.ylabel('Number post available', size = 12)\n",
    "plt.title('Total post each personality type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T23:26:36.389580Z",
     "start_time": "2023-12-03T23:26:27.847437Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "words = list(MBTI_DS[\"posts\"].apply(lambda x: x.split()))\n",
    "words = [x for y in words for x in y]\n",
    "wc = wordcloud.WordCloud(width=1200, height=500, collocations=False, background_color=\"white\", colormap=\"tab20b\").generate(\" \".join(words))\n",
    "\n",
    "# collocations to False  is set to ensure that the word cloud doesn't appear as if it contains any duplicate words\n",
    "plt.figure(figsize=(25,10))\n",
    "# generate word cloud, interpolation\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "_ = plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T23:26:40.471553Z",
     "start_time": "2023-12-03T23:26:36.389580Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(len(MBTI_DS['type'].unique()), figsize=(15,len(MBTI_DS['type'].unique())))\n",
    "k = 0\n",
    "for i in MBTI_DS['type'].unique():\n",
    "    df_4 = MBTI_DS[MBTI_DS['type'] == i]\n",
    "    wordcloud = WordCloud(max_words=1628,relative_scaling=1,normalize_plurals=False).generate(df_4['posts'].to_string())\n",
    "    plt.subplot(4,4,k+1)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.title(i)\n",
    "    ax[k].axis(\"off\")\n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T23:26:41.736938Z",
     "start_time": "2023-12-03T23:26:40.471553Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def get_types(row):\n",
    "    t=row['type']\n",
    "\n",
    "    I = 0; N = 0\n",
    "    T = 0; J = 0\n",
    "\n",
    "    if t[0] == 'I': I = 1\n",
    "    elif t[0] == 'E': I = 0\n",
    "    else: print('I-E not found')\n",
    "\n",
    "    if t[1] == 'N': N = 1\n",
    "    elif t[1] == 'S': N = 0\n",
    "    else: print('N-S not found')\n",
    "\n",
    "    if t[2] == 'T': T = 1\n",
    "    elif t[2] == 'F': T = 0\n",
    "    else: print('T-F not found')\n",
    "\n",
    "    if t[3] == 'J': J = 1\n",
    "    elif t[3] == 'P': J = 0\n",
    "    else: print('J-P not found')\n",
    "    return pd.Series( {'IE':I, 'NS':N , 'TF': T, 'JP': J })\n",
    "\n",
    "MBTI_DS_N = MBTI_DS.join(MBTI_DS.apply (lambda row: get_types (row),axis=1))\n",
    "MBTI_DS_N.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T23:26:41.991730Z",
     "start_time": "2023-12-03T23:26:41.736938Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "N = 4\n",
    "bottom = (MBTI_DS_N['IE'].value_counts()[0], MBTI_DS_N['NS'].value_counts()[0], MBTI_DS_N['TF'].value_counts()[0], MBTI_DS_N['JP'].value_counts()[0])\n",
    "top = (MBTI_DS_N['IE'].value_counts()[1], MBTI_DS_N['NS'].value_counts()[1], MBTI_DS_N['TF'].value_counts()[1], MBTI_DS_N['JP'].value_counts()[1])\n",
    "\n",
    "ind = np.arange(N)    # the x locations for the groups\n",
    "# the width of the bars\n",
    "width = 0.7\n",
    "\n",
    "p1 = plt.bar(ind, bottom, width, label=\"I, N, T, F\")\n",
    "p2 = plt.bar(ind, top, width, bottom=bottom, label=\"E, S, F, P\")\n",
    "\n",
    "plt.title('Distribution accoss types indicators')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(ind, ('I / E',  'N / S', 'T / F', 'J / P',))\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T23:26:41.991730Z",
     "start_time": "2023-12-03T23:26:41.866804Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Splitting the MBTI personality into 4 letters and binarizing it\n",
    "\n",
    "b_Pers = {'I':0, 'E':1, 'N':0, 'S':1, 'F':0, 'T':1, 'J':0, 'P':1}\n",
    "b_Pers_list = [{0:'I', 1:'E'}, {0:'N', 1:'S'}, {0:'F', 1:'T'}, {0:'J', 1:'P'}]\n",
    "\n",
    "def translate_personality(personality):\n",
    "    # Transform MBTI to binary vector\n",
    "    return [b_Pers[l] for l in personality]\n",
    "\n",
    "#Show result output for personality prediction\n",
    "def translate_back(personality):\n",
    "    # transform binary vector to MBTI personality\n",
    "    s = \"\"\n",
    "    for i, l in enumerate(personality):\n",
    "        s += b_Pers_list[i][l]\n",
    "    return s\n",
    "\n",
    "list_personality_bin = np.array([translate_personality(p) for p in MBTI_DS_N.type])\n",
    "print(\"Binarize MBTI list: \\n%s\" % list_personality_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T23:26:42.109291Z",
     "start_time": "2023-12-03T23:26:41.869545Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "useless_words = stopwords.words(\"english\")\n",
    "unique_type_list = ['INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ', 'ENFJ', 'INFP', 'ENFP','ISFP', 'ISTP', 'ISFJ', 'ISTJ', 'ESTP', 'ESFP', 'ESTJ', 'ESFJ']\n",
    "unique_type_list = [x.lower() for x in unique_type_list]\n",
    "lemmatiser = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T23:27:04.713629Z",
     "start_time": "2023-12-03T23:26:42.064935Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def pre_process_text(MBTI_DS_N, remove_stop_words=True, remove_mbti_profiles=True):\n",
    "  list_personality = []\n",
    "  list_posts = []\n",
    "  len_MBTI_DS_N = len(MBTI_DS_N)\n",
    "  i=0\n",
    "\n",
    "  for row in MBTI_DS_N.iterrows():\n",
    "      #Remove and clean comments\n",
    "      posts = row[1].posts\n",
    "\n",
    "      #Remove url links\n",
    "      temp = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', posts)\n",
    "\n",
    "      #Remove Non-words - keep only words\n",
    "      temp = re.sub(\"[^a-zA-Z]\", \" \", temp)\n",
    "\n",
    "      # Remove spaces > 1\n",
    "      temp = re.sub(' +', ' ', temp).lower()\n",
    "\n",
    "      #Remove multiple letter repeating words\n",
    "      temp = re.sub(r'([a-z])\\1{2,}[\\s|\\w]*', '', temp)\n",
    "\n",
    "      #Remove stop words\n",
    "      if remove_stop_words:\n",
    "          temp = \" \".join([lemmatiser.lemmatize(w) for w in temp.split(' ') if w not in useless_words])\n",
    "      else:\n",
    "          temp = \" \".join([lemmatiser.lemmatize(w) for w in temp.split(' ')])\n",
    "\n",
    "      #Remove MBTI personality words from posts\n",
    "      if remove_mbti_profiles:\n",
    "          for t in unique_type_list:\n",
    "              temp = temp.replace(t,\"\")\n",
    "\n",
    "      # transform mbti to binary vector\n",
    "      type_labelized = translate_personality(row[1].type) #or use lab_encoder.transform([row[1].type])[0]\n",
    "      list_personality.append(type_labelized)\n",
    "      # the cleaned data temp is passed here\n",
    "      list_posts.append(temp)\n",
    "\n",
    "  # returns the result\n",
    "  list_posts = np.array(list_posts)\n",
    "  list_personality = np.array(list_personality)\n",
    "  return list_posts, list_personality\n",
    "\n",
    "list_posts, list_personality  = pre_process_text(MBTI_DS_N, remove_stop_words=True, remove_mbti_profiles=True)\n",
    "\n",
    "print(\"Example :\")\n",
    "print(\"\\nPost before preprocessing:\\n\\n\", MBTI_DS_N.posts[0])\n",
    "print(\"\\nPost after preprocessing:\\n\\n\", list_posts[0])\n",
    "print(\"\\nMBTI before preprocessing:\\n\\n\", MBTI_DS_N.type[0])\n",
    "print(\"\\nMBTI after preprocessing:\\n\\n\", list_personality[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T23:27:06.286622Z",
     "start_time": "2023-12-03T23:27:04.714627Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Vectorizing the database posts to a matrix of token counts for the model\n",
    "cntizer = CountVectorizer(analyzer=\"word\",\n",
    "                             max_features=1000,\n",
    "                             max_df=0.7,\n",
    "                             min_df=0.1)\n",
    "# the feature should be made of word n-gram\n",
    "\n",
    "# Learn the vocabulary dictionary and return term-document matrix\n",
    "print(\"Using CountVectorizer :\")\n",
    "X_cnt = cntizer.fit_transform(list_posts)\n",
    "\n",
    "#The enumerate object yields pairs containing a count and a value (useful for obtaining an indexed list)\n",
    "feature_names = list(enumerate(cntizer.get_feature_names_out()))\n",
    "print(\"10 feature names can be seen below\")\n",
    "print(feature_names[0:10])\n",
    "\n",
    "# For the Standardization or Feature Scaling Stage :-\n",
    "# Transform the count matrix to a normalized tf or tf-idf representation\n",
    "tfizer = TfidfTransformer()\n",
    "\n",
    "# Learn the idf vector (fit) and transform a count matrix to a tf-idf representation\n",
    "print(\"\\nUsing Tf-idf :\")\n",
    "\n",
    "print(\"Now the dataset size is as below\")\n",
    "X_tfidf =  tfizer.fit_transform(X_cnt).toarray()\n",
    "print(X_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T23:27:39.394526Z",
     "start_time": "2023-12-03T23:27:39.379535Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "X = X_tfidf\n",
    "Y = list_personality[:,]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
    "personality_type = [ \"IE: Introversion (I) | Extroversion (E)\", \"NS: Intuition    (N) | Sensing      (S)\",\n",
    "                   \"FT: Feeling      (F) | Thinking     (T)\", \"JP: Judging      (J) | Perceiving   (P)\"  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T23:27:06.684871Z",
     "start_time": "2023-12-03T23:27:06.275597Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Logistic Regression for MBTI dataset\n",
    "# Individually training each mbti personlity type\n",
    "for l in range(len(personality_type)):\n",
    "\n",
    "    Y = list_personality[:,l]\n",
    "\n",
    "    # split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)\n",
    "\n",
    "    # fit model on training data\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # make predictions for test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    # evaluate predictions\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "    print(\"%s Accuracy: %.2f%%\" % (personality_type[l], accuracy * 100.0))\n",
    "    print(\"%s Classification report for Train Data\" % (personality_type[l]))\n",
    "    print(classification_report(y_train,model.predict(X_train)))\n",
    "    print(\"%s Classification report for Test Data\" % (personality_type[l]))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T23:29:56.841536Z",
     "start_time": "2023-12-03T23:29:55.930255Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "for l in range(len(personality_type)):\n",
    "\n",
    "    Y = list_personality[:,l]\n",
    "\n",
    "    # split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=7)\n",
    "\n",
    "    # fit model on training data\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # make predictions for test data\n",
    "    y_pred = model.predict_proba(X_test)[:,1] # use predict_proba instead of predict for ROC curve\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "\n",
    "    plt.title('%s ROC Curve' % (personality_type[l]))\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T23:33:12.441668Z",
     "start_time": "2023-12-03T23:32:56.137301Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#KNN Classifier\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "\n",
    "# Tuning of K- value for Train & Test data\n",
    "dummyarray = np.empty((5,3))\n",
    "k_valchart = pd.DataFrame(dummyarray)\n",
    "k_valchart.columns = [\"K_value\",\"Train_acc\",\"Test_acc\"]\n",
    "k_vals = range(1, 10)\n",
    "for i in range(len(k_vals)):\n",
    "    knn_fit = KNeighborsClassifier(n_neighbors=k_vals[i])\n",
    "    knn_fit.fit(X_train,y_train)\n",
    "    print (\"\\nK-value\",k_vals[i])\n",
    "    tr_accscore = round(accuracy_score(y_train,knn_fit.predict(X_train)),3)\n",
    "    print (\"\\nK-Nearest Neighbors - Train ConfusionMatrix\\n\\n\",pd.crosstab( y_train, knn_fit.predict(X_train),rownames =[\"Actuall\"],colnames = [\"Predicted\"]) )\n",
    "    print (\"\\nK-Nearest Neighbors - Train accuracy:\",tr_accscore)\n",
    "    print (\"\\nK-Nearest Neighbors - Train Classification Report\\n\",classification_report(y_train,knn_fit.predict(X_train)))\n",
    "    ts_accscore = round(accuracy_score(y_test,knn_fit.predict(X_test)),3)\n",
    "    print (\"\\n\\nK-Nearest Neighbors - Test Confusion Matrix\\n\\n\",pd.crosstab( y_test,knn_fit.predict(X_test),rownames =[\"Actuall\"],colnames = [\"Predicted\"]))\n",
    "    print (\"\\nK-Nearest Neighbors - Test accuracy:\",ts_accscore)\n",
    "    print (\"\\nK-Nearest Neighbors - Test Classification Report\\n\",classification_report(y_test,knn_fit.predict(X_test)))\n",
    "    k_valchart.loc[i, 'K_value'] = k_vals[i]\n",
    "    k_valchart.loc[i, 'Train_acc'] = tr_accscore\n",
    "    k_valchart.loc[i, 'Test_acc'] = ts_accscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T23:33:13.530261Z",
     "start_time": "2023-12-03T23:33:13.401962Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot the train and test accuracy scores for different K-values\n",
    "plt.plot(k_valchart['K_value'], k_valchart['Train_acc'], label='Train accuracy')\n",
    "plt.plot(k_valchart['K_value'], k_valchart['Test_acc'], label='Test accuracy')\n",
    "plt.xlabel('K-value')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(k_valchart['K_value'])\n",
    "plt.xticks(k_vals)\n",
    "for a,b in zip(k_valchart[\"K_value\"],k_valchart[\"Train_acc\"]):\n",
    "    plt.text(a, b, str(b),fontsize=10)\n",
    "for a,b in zip(k_valchart[\"K_value\"],k_valchart[\"Test_acc\"]):\n",
    "    plt.text(a, b, str(b),fontsize=10)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Now use a Random Forest on the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T20:38:47.841938Z",
     "start_time": "2023-12-03T20:38:47.630558Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Use MBTI personality to build a single model\n",
    "list_personality_full = []\n",
    "for row in MBTI_DS_N.iterrows():\n",
    "    list_personality_full.append(row[1].type)\n",
    "list_personality_full = np.array(list_personality_full)\n",
    "list_personality_full[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T23:42:08.573959Z",
     "start_time": "2023-12-03T23:41:31.238777Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Apply Random Forest\n",
    "Y = list_personality_full[:,]\n",
    "personalities = ['INFP','INFJ','INTP','INTJ','ENTP','ENFP','ISTP','ISFP','ENTJ','ISTJ','ENFJ','ISFJ','ESTP','ESFP','ESFJ','ESTJ']\n",
    "for p in personalities:\n",
    "    Y_NEW = []\n",
    "    for i in range(len(Y)):\n",
    "        Y_NEW.append(1 if Y[i]==p else 0)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y_NEW, test_size=0.3, random_state=0)\n",
    "\n",
    "    clf = RandomForestClassifier(max_depth=4)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(p)\n",
    "    # print(clf.score(X_test, y_test))\n",
    "\n",
    "    tr_accscore = round(accuracy_score(y_train, clf.predict(X_train)), 4)\n",
    "    # print (\"\\nRandom Forest - Train ConfusionMatrix\\n\\n\",pd.crosstab( y_train, clf.predict(X_train),rownames =[\"Actuall\"],colnames = [\"Predicted\"]) )\n",
    "    print (\"\\nRandom Forest - Train accuracy:\",tr_accscore)\n",
    "    print (\"Random Forest - Train Classification Report\\n\",classification_report(y_train,clf.predict(X_train)))\n",
    "    ts_accscore = round(accuracy_score(y_test,clf.predict(X_test)),4)\n",
    "    # print (\"\\n\\nRandom Forest - Test Confusion Matrix\\n\\n\",pd.crosstab( y_test,clf.predict(X_test),rownames =[\"Actuall\"],colnames = [\"Predicted\"]))\n",
    "    print (\"\\nRandom Forest - Test accuracy:\",ts_accscore)\n",
    "    print (\"Random Forest - Test Classification Report\\n\",classification_report(y_test,clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Now use a bigger dataset with 100 thousand data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T23:46:40.149488Z",
     "start_time": "2023-12-03T23:46:36.928995Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "MBTI_DS_BIG = pd.read_csv(\"MBTI 500.csv\")\n",
    "MBTI_DS_BIG.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T23:46:48.815601Z",
     "start_time": "2023-12-03T23:46:40.148446Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "posts = []\n",
    "labels = []\n",
    "for row in MBTI_DS_BIG.iterrows():\n",
    "    temp = row[1].posts\n",
    "\n",
    "    # Remove MBTI words from posts\n",
    "    for t in unique_type_list:\n",
    "        temp = temp.replace(t,\"\")\n",
    "\n",
    "    posts.append(temp)\n",
    "    labels.append(row[1].type)\n",
    "\n",
    "posts = np.array(posts)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T23:47:11.015467Z",
     "start_time": "2023-12-03T23:46:48.816617Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Learn the vocabulary dictionary and return term-document matrix\n",
    "print(\"Using CountVectorizer :\")\n",
    "X_count = cntizer.fit_transform(posts)\n",
    "\n",
    "#The enumerate object yields pairs containing a count and a value (useful for obtaining an indexed list)\n",
    "feature_names = list(enumerate(cntizer.get_feature_names_out()))\n",
    "print(\"10 feature names can be seen below\")\n",
    "print(feature_names[0:10])\n",
    "\n",
    "# Learn the idf vector (fit) and transform a count matrix to a tf-idf representation\n",
    "print(\"\\nUsing Tf-idf :\")\n",
    "\n",
    "print(\"Now the dataset size is as below\")\n",
    "X_new_tfidf =  tfizer.fit_transform(X_count).toarray()\n",
    "print(X_new_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T20:50:08.939464Z",
     "start_time": "2023-11-28T20:39:32.363031Z"
    },
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "X = X_new_tfidf\n",
    "Y = labels\n",
    "\n",
    "for p in personalities:\n",
    "    Y_NEW = []\n",
    "    for i in range(len(Y)):\n",
    "        Y_NEW.append(1 if Y[i]==p else 0)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y_NEW, test_size=0.2, random_state=0)\n",
    "\n",
    "    clf1 = RandomForestClassifier(max_depth=4)\n",
    "    # clf2 = LogisticRegression()\n",
    "    clf1.fit(X_train, y_train)\n",
    "    # clf2.fit(X_train, y_train)\n",
    "    print(p)\n",
    "    # print(\"Random Forest: \", clf1.score(X_test, y_test))\n",
    "    # print(\"Logistic Regression: \", clf2.score(X_test, y_test))\n",
    "    trr = clf1.predict(X_train)\n",
    "    tee = clf1.predict(X_test)\n",
    "    tr_accscore = round(accuracy_score(y_train, trr), 4)\n",
    "    # print (\"\\nRandom Forest - Train ConfusionMatrix\\n\\n\",pd.crosstab( y_train, clf.predict(X_train),rownames =[\"Actuall\"],colnames = [\"Predicted\"]) )\n",
    "    print (\"\\nRandom Forest - Train accuracy:\", tr_accscore)\n",
    "    print (\"Random Forest - Train Classification Report\\n\",classification_report(y_train,trr))\n",
    "    ts_accscore = round(accuracy_score(y_test, tee),4)\n",
    "    # print (\"\\n\\nRandom Forest - Test Confusion Matrix\\n\\n\",pd.crosstab( y_test,clf.predict(X_test),rownames =[\"Actuall\"],colnames = [\"Predicted\"]))\n",
    "    print (\"Random Forest - Test accuracy:\",ts_accscore)\n",
    "    print (\"Random Forest - Test Classification Report\\n\",classification_report(y_test, tee))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# After Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "total = MBTI_DS_BIG.groupby(['type']).count()\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.bar(np.array(total.index), height=total['posts'], )\n",
    "plt.xlabel('Personality types', size=12)\n",
    "plt.ylabel('Number post available', size=12)\n",
    "plt.title('Total post each personality type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "int((total.mean())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "target_size = total.min()[0]\n",
    "\n",
    "# Undersample each class to the target size\n",
    "undersampled_data = pd.DataFrame()\n",
    "for mbti_type, group in MBTI_DS_BIG.groupby('type'):\n",
    "    undersampled_group = resample(group, replace=False, n_samples=target_size, random_state=42)\n",
    "    undersampled_data = pd.concat([undersampled_data, undersampled_group])\n",
    "\n",
    "# Shuffle the undersampled data\n",
    "undersampled_data = undersampled_data.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "posts_undersampled = []\n",
    "labels_undersampled = []\n",
    "for row in undersampled_data.iterrows():\n",
    "    temp = row[1].posts\n",
    "\n",
    "    # Remove MBTI words from posts\n",
    "    for t in unique_type_list:\n",
    "        temp = temp.replace(t, \"\")\n",
    "\n",
    "    posts_undersampled.append(temp)\n",
    "    labels_undersampled.append(row[1].type)\n",
    "\n",
    "posts_undersampled = np.array(posts_undersampled)\n",
    "labels_undersampled = np.array(labels_undersampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Learn the vocabulary dictionary and return term-document matrix\n",
    "print(\"Using CountVectorizer :\")\n",
    "X_count_unders = cntizer.fit_transform(posts_undersampled)\n",
    "\n",
    "#The enumerate object yields pairs containing a count and a value (useful for obtaining an indexed list)\n",
    "feature_names_unders = list(enumerate(cntizer.get_feature_names_out()))\n",
    "print(\"10 feature names can be seen below\")\n",
    "print(feature_names_unders[0:10])\n",
    "\n",
    "# Learn the idf vector (fit) and transform a count matrix to a tf-idf representation\n",
    "print(\"\\nUsing Tf-idf :\")\n",
    "\n",
    "print(\"Now the dataset size is as below\")\n",
    "X_new_tfidf_unders = tfizer.fit_transform(X_count_unders).toarray()\n",
    "print(X_new_tfidf_unders.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "X = X_new_tfidf_unders\n",
    "Y = labels_undersampled\n",
    "\n",
    "for p in personalities:\n",
    "    Y_NEW = []\n",
    "    for i in range(len(Y)):\n",
    "        Y_NEW.append(1 if Y[i] == p else 0)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y_NEW, test_size=0.2, random_state=0)\n",
    "\n",
    "    clf1 = RandomForestClassifier(max_depth=4)\n",
    "    clf2 = LogisticRegression()\n",
    "    clf1.fit(X_train, y_train)\n",
    "    clf2.fit(X_train, y_train)\n",
    "    print(p)\n",
    "    print(\"Random Forest: \", clf1.score(X_test, y_test))\n",
    "    print(\"Logistic Regression: \", clf2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# For comparison purpose, we want to visualize \n",
    "# 'Performance Scores of Logistic Regression and Random Forest by MBTI Type' before resampling first\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Since the image contains tabular data, we will manually input the data based on the image provided.\n",
    "\n",
    "# Data extracted from the image\n",
    "data = {\n",
    "    \"Model\": [\"Logistic Regression\", \"Random Forest\"],\n",
    "    \"INFP\": [0.887, 0.897],\n",
    "    \"INFJ\": [0.886, 0.878],\n",
    "    \"INTP\": [0.766, 0.8],\n",
    "    \"INTJ\": [0.787, 0.817],\n",
    "    \"ENTP\": [0.889, 0.906],\n",
    "    \"ENFP\": [0.942, 0.944],\n",
    "    \"ISTP\": [0.969, 0.97],\n",
    "    \"ISFP\": [0.992, 0.992],\n",
    "    \"ENTJ\": [0.971, 0.972],\n",
    "    \"ISTJ\": [0.989, 0.989],\n",
    "    \"ENFJ\": [0.985, 0.985],\n",
    "    \"ISFJ\": [0.994, 0.994],\n",
    "    \"ESTP\": [0.981, 0.987],\n",
    "    \"ESFP\": [0.996, 0.996],\n",
    "    \"ESFJ\": [0.998, 0.998],\n",
    "    \"ESTJ\": [0.995, 0.996],\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Melt the DataFrame to make it suitable for a barplot\n",
    "df_melted = df.melt(id_vars=\"Model\", var_name=\"MBTI Type\", value_name=\"Score\")\n",
    "\n",
    "# Initialize the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "# Draw a barplot to show the score for each MBTI type by model\n",
    "sns.barplot(x=\"MBTI Type\", y=\"Score\", hue=\"Model\", data=df_melted)\n",
    "\n",
    "# Improve the visuals\n",
    "ax.set_title('Performance Scores of Logistic Regression and Random Forest by MBTI Type')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_xlabel('MBTI Type')\n",
    "sns.despine(left=True, bottom=True)\n",
    "\n",
    "# Rotate the x labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/local/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# For comparison purpose, we want to visualize \n",
    "# 'Performance Scores of Logistic Regression and Random Forest by MBTI Type' before resampling first\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Since the image contains tabular data, we will manually input the data based on the image provided.\n",
    "\n",
    "# Data extracted from the image\n",
    "data = {\n",
    "    \"Model\": [\"Logistic Regression\", \"Random Forest\"],\n",
    "    \"INFP\": [0.887, 0.897],\n",
    "    \"INFJ\": [0.886, 0.878],\n",
    "    \"INTP\": [0.766, 0.8],\n",
    "    \"INTJ\": [0.787, 0.817],\n",
    "    \"ENTP\": [0.889, 0.906],\n",
    "    \"ENFP\": [0.942, 0.944],\n",
    "    \"ISTP\": [0.969, 0.97],\n",
    "    \"ISFP\": [0.992, 0.992],\n",
    "    \"ENTJ\": [0.971, 0.972],\n",
    "    \"ISTJ\": [0.989, 0.989],\n",
    "    \"ENFJ\": [0.985, 0.985],\n",
    "    \"ISFJ\": [0.994, 0.994],\n",
    "    \"ESTP\": [0.981, 0.987],\n",
    "    \"ESFP\": [0.996, 0.996],\n",
    "    \"ESFJ\": [0.998, 0.998],\n",
    "    \"ESTJ\": [0.995, 0.996],\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Melt the DataFrame to make it suitable for a barplot\n",
    "df_melted = df.melt(id_vars=\"Model\", var_name=\"MBTI Type\", value_name=\"Score\")\n",
    "\n",
    "# Initialize the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "# Draw a barplot to show the score for each MBTI type by model\n",
    "sns.barplot(x=\"MBTI Type\", y=\"Score\", hue=\"Model\", data=df_melted)\n",
    "\n",
    "# Improve the visuals\n",
    "ax.set_title('Performance Scores of Logistic Regression and Random Forest by MBTI Type')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_xlabel('MBTI Type')\n",
    "sns.despine(left=True, bottom=True)\n",
    "\n",
    "# Rotate the x labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
